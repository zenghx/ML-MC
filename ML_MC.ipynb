{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-MC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjC_QAPCIxJp",
        "colab_type": "text"
      },
      "source": [
        "将github中的repo clone过来运行，左侧文件里有就不需要运行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLND_tz_Hu0N",
        "colab_type": "code",
        "outputId": "d01736c3-4f46-4036-c6fe-296bb85e18f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!git clone https://github.com/zenghx/ML-MC.git\n",
        "import os\n",
        "os.chdir(\"/content/ML-MC\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML-MC'...\n",
            "remote: Enumerating objects: 24336, done.\u001b[K\n",
            "remote: Counting objects: 100% (24336/24336), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24328/24328), done.\u001b[K\n",
            "remote: Total 24336 (delta 10), reused 24316 (delta 3), pack-reused 0\n",
            "Receiving objects: 100% (24336/24336), 371.76 MiB | 33.25 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "Checking out files: 100% (24339/24339), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxsQb8QFVK_-",
        "colab_type": "text"
      },
      "source": [
        "###将文件转换为tfRecord\n",
        "参照了[这个](https://www.cnblogs.com/wyh1993/p/6703135.html)和\n",
        "[猫狗大战](https://www.cnblogs.com/ansang/p/9126427.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w7NqK4mUPRJ",
        "colab_type": "code",
        "outputId": "2a3ca775-3d2f-4530-b542-d156e910a9fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from skimage import io,color,transform\n",
        "\n",
        "def _int64_feature(value):\n",
        "    if not isinstance(value,list):\n",
        "        value=[value]\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "def _byte_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def to_tfrecord(data_path,dest_path):\n",
        "  os.chdir(data_path)\n",
        "  folders=os.listdir()\n",
        "  folders.sort()\n",
        "  i=0\n",
        "  with tf.python_io.TFRecordWriter(dest_path) as writer:\n",
        "    for folder in folders:\n",
        "      path=data_path+\"/\"+folder\n",
        "      img_paths=glob.glob(os.path.join(path,\"*.jpg\"))\n",
        "      for img_path in img_paths:\n",
        "        img=io.imread(img_path)\n",
        "        img=color.rgb2gray(img)\n",
        "        img = transform.resize(img, [150, 150])\n",
        "        if 3 == img.ndim:\n",
        "          rows, cols, depth = img.shape\n",
        "        else:\n",
        "          rows, cols = img.shape\n",
        "          depth = 1\n",
        "        labels=[0]*6\n",
        "        labels[i]=1\n",
        "        example=tf.train.Example(features=tf.train.Features(feature={\n",
        "            'width':_int64_feature(cols),\n",
        "            'height':_int64_feature(rows),\n",
        "            'depth':_int64_feature(depth),\n",
        "            'image_raw':_byte_feature(img.astype(np.float32).tobytes()),\n",
        "            'label':_int64_feature(labels)}))\n",
        "        writer.write(example.SerializeToString())#把example加入到writer里，最后写到磁盘。\n",
        "      i=i+1\n",
        "  writer.close()\n",
        "  print(dest_path+\" has been written successfully!\")\n",
        "to_tfrecord(\"/content/ML-MC/seg_train\",\"/content/ML-MC/train.record\")     \n",
        "to_tfrecord(\"/content/ML-MC/seg_test\",\"/content/ML-MC/test.record\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ML-MC/train.record has been written successfully!\n",
            "/content/ML-MC/test.record has been written successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdmIhRVtYVPy",
        "colab_type": "text"
      },
      "source": [
        "###训练模型\n",
        "参照[tensorflow:input pipeline性能指南\n",
        "](http://d0evi1.com/tensorflow/datasets_performance/)和[猫狗大战](https://www.cnblogs.com/ansang/p/9126427.html)、[Tensorflow实战系列：手把手教你使用CNN进行图像分类（附完整代码）\n",
        "](https://cloud.tencent.com/developer/article/1086770)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrekR2Acq_5L",
        "colab_type": "code",
        "outputId": "6f85bec8-03c1-4cf3-d440-958f652abef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "def input_fn(mode, batch_size=1):\n",
        "\n",
        "  def parser(serialized_example):\n",
        "    features = tf.parse_single_example(serialized_example,\n",
        "    features={\n",
        "          'width':tf.FixedLenFeature([], tf.int64),\n",
        "          'height':tf.FixedLenFeature([], tf.int64),\n",
        "          'depth':tf.FixedLenFeature([], tf.int64),\n",
        "          'image_raw':tf.FixedLenFeature([],tf.string),\n",
        "          'label':tf.FixedLenFeature([],tf.int64)})\n",
        "    image=tf.decode_raw(features['image_raw'],tf.float32)\n",
        "    depth = tf.cast(features['depth'], tf.int32)\n",
        "    width = tf.cast(features['width'], tf.int32)\n",
        "    height= tf.cast(features['height'], tf.int32)\n",
        "    image = tf.reshape(image, [height,width, depth])\n",
        "    image=image-0.5\n",
        "    label=tf.cast(features['label'],tf.int32)\n",
        "    return image,label\n",
        "  tfrecords_file =\"content/ML-MC/test.record\"\n",
        "  dataset = tf.data.TFRecordDataset([tfrecords_file])\n",
        "  dataset = dataset.map(parser, num_parallel_calls=1)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  if mode == \"train\":\n",
        "    dataset = dataset.repeat()\n",
        "  iterator = dataset.make_one_shot_iterator()\n",
        "  images, labels = iterator.get_next()\n",
        "  if len(images)==len(labels)\n",
        "    print(\"OK\")\n",
        "  return images, labels\n",
        "\n",
        "input_fn(mode=none)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-e3783880494a>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    if len(images)==len(labels)\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ibh2-a2vvv",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKHy0d0Fm96b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "1592a259-6cb0-4162-ee1f-8ba7848b8b5d"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "batch_size=10\n",
        "model_dir='/content/ML-MC/Model'\n",
        "classes=6\n",
        "\n",
        "\n",
        "MODES = [tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL, tf.estimator.ModeKeys.PREDICT]\n",
        "\n",
        "\n",
        "def input_fn(mode, batch_size=1):\n",
        "    \"\"\"输入函数\"\"\"\n",
        "\n",
        "    def parser(serialized_example):\n",
        "        \"\"\"如何处理数据集中的每一个数据\"\"\"\n",
        "\n",
        "        # 解析单个example对象\n",
        "        features = tf.parse_single_example(\n",
        "            serialized_example,\n",
        "            features={\n",
        "                'width':tf.FixedLenFeature([], tf.int64),\n",
        "                'height':tf.FixedLenFeature([], tf.int64),\n",
        "                'depth':tf.FixedLenFeature([], tf.int64),\n",
        "                'image_raw':tf.FixedLenFeature([],tf.string),\n",
        "                'label':tf.FixedLenFeature([6],tf.int64)\n",
        "            })\n",
        "\n",
        "        # 获取参数\n",
        "        depth = tf.cast(features['depth'], tf.int64)\n",
        "        height = tf.cast(features['height'], tf.int64)\n",
        "        width = tf.cast(features['width'], tf.int64)\n",
        "\n",
        "        # 还原image\n",
        "        image = tf.decode_raw(features['image_raw'], tf.float32)\n",
        "        image = tf.reshape(image, [height,width, depth])\n",
        "        image = image - 0.5\n",
        "\n",
        "        # 还原label\n",
        "        label = tf.cast(features['label'], tf.int32)\n",
        "        return image, label\n",
        "\n",
        "    if mode==tf.estimator.ModeKeys.TRAIN:\n",
        "        tfrecords_file = \"/content/ML-MC/train.record\"\n",
        "    elif mode==tf.estimator.ModeKeys.EVAL:\n",
        "        tfrecords_file = \"/content/ML-MC/test.record\"\n",
        "    else:\n",
        "        raise ValueError(\"Mode 未知\")\n",
        "\n",
        "    \n",
        "\n",
        "    # 创建数据集\n",
        "    dataset = tf.data.TFRecordDataset([tfrecords_file])\n",
        "    # 创建映射\n",
        "    dataset = dataset.map(parser, num_parallel_calls=2)\n",
        "    # 设置batch\n",
        "    dataset = dataset.shuffle(buffer_size= 14034).batch(batch_size).prefetch(1000)\n",
        "    # 如果是训练，那么就永久循环下去\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        dataset = dataset.repeat()\n",
        "    # 创建迭代器\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    # 获取 feature 和 label\n",
        "    images, labels = iterator.get_next()\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "def my_model(inputs, mode):\n",
        "    \"\"\"写一个网络\"\"\"\n",
        "    net = tf.reshape(inputs, [-1, 150,150, 1])\n",
        "    net = tf.layers.conv2d(net, 32, [5, 5], padding='same', activation=tf.nn.relu)\n",
        "    net = tf.layers.max_pooling2d(net, [3, 3], strides=2)\n",
        "    net = tf.layers.conv2d(net, 32, [5, 5], padding='same', activation=tf.nn.relu)\n",
        "    net = tf.layers.max_pooling2d(net, [3, 3], strides=2)\n",
        "    net = tf.layers.conv2d(net, 64, [5, 5], padding='same', activation=tf.nn.relu)\n",
        "    net = tf.layers.conv2d(net, 64, [5, 5], padding='same', activation=tf.nn.relu)\n",
        "    net = tf.layers.max_pooling2d(net, [3, 3], strides=2)\n",
        "    #print(net)\n",
        "    net = tf.reshape(net, [-1, 17*17*64])\n",
        "    net = tf.layers.dense(net, 1024, activation=tf.nn.relu)\n",
        "    net = tf.layers.dropout(net, 0.4, training=(mode == tf.estimator.ModeKeys.TRAIN))    \n",
        "    net = tf.layers.dense(net, classes)\n",
        "    return net\n",
        "\n",
        "\n",
        "def my_model_fn(features, labels, mode):\n",
        "    \"\"\"模型函数\"\"\"\n",
        "\n",
        "    # 可视化输入\n",
        "    tf.summary.image('images', features)\n",
        "\n",
        "    # 创建网络\n",
        "    logits = my_model(features, mode)\n",
        "    predictions = {\n",
        "        'classes': tf.argmax(input=logits, axis=1),\n",
        "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
        "    }\n",
        "\n",
        "    # 如果是PREDICT，那么只需要predictions就够了\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    # 创建Loss\n",
        "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits, scope='loss')\n",
        "    tf.summary.scalar('train_loss', loss)\n",
        "\n",
        "    # 设置如何训练\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
        "        train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())\n",
        "    else:\n",
        "        train_op = None\n",
        "\n",
        "    # 获取训练精度\n",
        "    accuracy = tf.metrics.accuracy(\n",
        "        tf.argmax(labels, axis=1), predictions['classes'],\n",
        "        name='accuracy')\n",
        "\n",
        "    accuracy_topk = tf.metrics.mean(\n",
        "        tf.nn.in_top_k(predictions['probabilities'], tf.argmax(labels, axis=1), 2),\n",
        "        name='accuracy_topk')\n",
        "\n",
        "    metrics = {\n",
        "        'test_accuracy': accuracy,\n",
        "        'test_accuracy_topk': accuracy_topk\n",
        "    }\n",
        "\n",
        "    # 可视化训练精度\n",
        "    tf.summary.scalar('train_accuracy', accuracy[1])\n",
        "    tf.summary.scalar('train_accuracy_topk', accuracy_topk[1])\n",
        "\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions=predictions,\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops=metrics)\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    # 监视器\n",
        "    logging_hook = tf.train.LoggingTensorHook(\n",
        "        every_n_iter=100,\n",
        "        tensors={\n",
        "            'accuracy': 'accuracy/value',\n",
        "            'accuracy_topk': 'accuracy_topk/value',\n",
        "            'loss': 'loss/value'\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # 创建 Estimator\n",
        "    model = tf.estimator.Estimator(\n",
        "        model_fn=my_model_fn,\n",
        "        model_dir=model_dir)\n",
        "\n",
        "    \n",
        "    \n",
        "    for i in range(5):\n",
        "        # 训练\n",
        "\n",
        "        model.train(\n",
        "            input_fn=lambda: input_fn(tf.estimator.ModeKeys.TRAIN,batch_size),\n",
        "            steps=1404,\n",
        "            hooks=[logging_hook])\n",
        "\n",
        "        # 测试并输出结果\n",
        "        print(\"=\" * 10, \"Testing\", \"=\" * 10)\n",
        "        eval_results = model.evaluate(\n",
        "            input_fn=lambda: input_fn(tf.estimator.ModeKeys.EVAL))\n",
        "        print('Evaluation results:\\n\\t{}'.format(eval_results))\n",
        "        print(\"=\" * 30)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #tf.logging.set_verbosity(tf.logging.INFO)\n",
        "    tf.app.run()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/ML-MC/Model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f12bb3e6550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/ML-MC/Model/model.ckpt.\n",
            "INFO:tensorflow:accuracy = 0.0, accuracy_topk = 0.0, loss = 1.790295\n",
            "INFO:tensorflow:loss = 1.790295, step = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIMcvLtQ0aC7",
        "colab_type": "code",
        "outputId": "4d13ef12-1fc3-45b1-e5f6-39300dc8f979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/ML-MC\")\n",
        "!pwd         \n",
        "!rm -rf Model"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ML-MC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PomMsicfB7KI",
        "colab_type": "code",
        "outputId": "5d2af6c0-e96f-487a-a72e-d30cb3232c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from skimage import io, transform, color, util\n",
        "\n",
        "mode = tf.estimator.ModeKeys.PREDICT\n",
        "_NUM_CLASSES = 2\n",
        "image_size = [150,150]\n",
        "label=[0]*6\n",
        "image_files = '/content/ML-MC/seg_train/buildings/315.jpg'\n",
        "model_dir = './ML-MC/'\n",
        "\n",
        "def main(unused_argv):\n",
        "  # Using the Winograd non-fused algorithms provides a small performance boost.\n",
        "  os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
        "  #\n",
        "  model = tf.estimator.Estimator(\n",
        "      model_fn=my_model_fn,\n",
        "      model_dir=model_dir)\n",
        "\n",
        "  def predict_input_fn(image_path):\n",
        "      img = io.imread(image_path)\n",
        "      img = color.rgb2gray(img)\n",
        "      img = transform.resize(img, [150, 150])\n",
        "      image = img - 0.5\n",
        "      # preprocess image: scale pixel values from 0-255 to 0-1\n",
        "      images = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "      dataset = tf.data.Dataset.from_tensors((images,))\n",
        "      return dataset.batch(1).make_one_shot_iterator().get_next(),label\n",
        "\n",
        "  def predict(image_path):\n",
        "\n",
        "      result = model.predict(input_fn=lambda: predict_input_fn(image_path=image_path))\n",
        "      for r in result:\n",
        "          print(r)\n",
        "\n",
        "  predict(image_files)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "  tf.app.run(main=main)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './ML-MC/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f12bbe9c6a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Could not find trained model in model_dir: ./ML-MC/, running initialization to predict.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "{'classes': 0, 'probabilities': array([0.1815517 , 0.15277357, 0.16160782, 0.16405028, 0.1669556 ,\n",
            "       0.17306107], dtype=float32)}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajGLH6KC26qw",
        "colab_type": "text"
      },
      "source": [
        "# 测试用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se-2P-uj3FKn",
        "colab_type": "code",
        "outputId": "7d9a6df6-e9a7-464c-e56d-30a3c33eb2e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tfrecord_path_none = \"/content/ML-MC/test.record\"\n",
        "\n",
        "filename_queues = tf.train.string_input_producer([tfrecord_path_none])\n",
        "\n",
        "# 定义不同压缩选项的TFRecordReader\n",
        "reader_none = tf.TFRecordReader(options=None)\n",
        "\n",
        "# 读取不同的tfrecord文件\n",
        "_,serialized_example_none = reader_none.read(filename_queues)\n",
        "\n",
        "# 根据key名字得到保存的features字典\n",
        "features_none = tf.parse_single_example(serialized_example_none,\n",
        "features={\n",
        "          'width':tf.FixedLenFeature([], tf.int64),\n",
        "          'height':tf.FixedLenFeature([], tf.int64),\n",
        "          'depth':tf.FixedLenFeature([], tf.int64),\n",
        "          'image_raw':tf.FixedLenFeature([],tf.string),\n",
        "          'label':tf.FixedLenFeature([6,1],tf.int64)\n",
        "})\n",
        "\n",
        "# 获取参数\n",
        "depth = tf.cast(features['depth'], tf.int64)\n",
        "height = tf.cast(features['height'], tf.int64)\n",
        "width = tf.cast(features['width'], tf.int64)\n",
        "\n",
        "        # 还原image\n",
        "image = tf.decode_raw(features['image_raw'], tf.float32)\n",
        "        image = tf.reshape(image, [height,width, depth])\n",
        "        image = image - 0.5\n",
        "# 启用队列协调管理器，并使用tf.train.start_queue_runners启动队列文件线程\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "coord = tf.train.Coordinator()\n",
        "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "image= sess.run(image)\n",
        "# 关闭线程以及会话\n",
        "coord.request_stop()\n",
        "coord.join(threads)\n",
        "sess.close()\n",
        "\n",
        "# 显示读取到的图片\n",
        "plt.imshow(image)\n",
        "plt.title(\"beautiful view\")\n",
        "plt.show()\n",
        "\n",
        "print(\"finish to read data from tfrecord file!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-c69b10a24af3>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    image = tf.reshape(image, [height,width, depth])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcdB5Gy1F6Qr",
        "colab_type": "text"
      },
      "source": [
        "#检测大小不统一的图片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEcWslds8A1R",
        "colab_type": "code",
        "outputId": "4f0d7b5a-d0a8-4401-ec8b-fde590aa631a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from skimage import io,color\n",
        "\n",
        "\n",
        "\n",
        "def check(data_path,dest_path):\n",
        "  os.chdir(data_path)\n",
        "  folders=os.listdir()\n",
        "  folders.sort()\n",
        "  i=0\n",
        "  with tf.python_io.TFRecordWriter(dest_path) as writer:\n",
        "    for folder in folders:\n",
        "      path=data_path+\"/\"+folder\n",
        "      img_paths=glob.glob(os.path.join(path,\"*.jpg\"))\n",
        "      for img_path in img_paths:\n",
        "        img=io.imread(img_path)\n",
        "        img=color.rgb2gray(img)\n",
        "        if 3 == img.ndim:\n",
        "          rows, cols, depth = img.shape\n",
        "        else:\n",
        "          rows, cols = img.shape\n",
        "          depth = 1\n",
        "        if cols!=150:\n",
        "          print(img_path,img.shape)\n",
        "        elif rows!=150:\n",
        "          print(img_path,img.shape)\n",
        "\n",
        "check(\"/content/ML-MC/seg_train\",\"/content/ML-MC/train.record\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ML-MC/seg_train/buildings/5358.jpg (124, 150)\n",
            "/content/ML-MC/seg_train/forest/5483.jpg (136, 150)\n",
            "/content/ML-MC/seg_train/forest/14315.jpg (133, 150)\n",
            "/content/ML-MC/seg_train/forest/5643.jpg (108, 150)\n",
            "/content/ML-MC/seg_train/forest/1004.jpg (113, 150)\n",
            "/content/ML-MC/seg_train/forest/14609.jpg (115, 150)\n",
            "/content/ML-MC/seg_train/forest/7174.jpg (113, 150)\n",
            "/content/ML-MC/seg_train/forest/15776.jpg (135, 150)\n",
            "/content/ML-MC/seg_train/forest/12108.jpg (108, 150)\n",
            "/content/ML-MC/seg_train/glacier/18110.jpg (102, 150)\n",
            "/content/ML-MC/seg_train/glacier/3148.jpg (97, 150)\n",
            "/content/ML-MC/seg_train/glacier/2837.jpg (76, 150)\n",
            "/content/ML-MC/seg_train/glacier/1010.jpg (110, 150)\n",
            "/content/ML-MC/seg_train/glacier/1740.jpg (134, 150)\n",
            "/content/ML-MC/seg_train/glacier/12983.jpg (120, 150)\n",
            "/content/ML-MC/seg_train/glacier/17654.jpg (119, 150)\n",
            "/content/ML-MC/seg_train/glacier/17611.jpg (123, 150)\n",
            "/content/ML-MC/seg_train/glacier/12634.jpg (111, 150)\n",
            "/content/ML-MC/seg_train/glacier/17528.jpg (142, 150)\n",
            "/content/ML-MC/seg_train/glacier/16710.jpg (146, 150)\n",
            "/content/ML-MC/seg_train/glacier/5135.jpg (111, 150)\n",
            "/content/ML-MC/seg_train/glacier/15103.jpg (149, 150)\n",
            "/content/ML-MC/seg_train/glacier/7512.jpg (135, 150)\n",
            "/content/ML-MC/seg_train/glacier/7410.jpg (111, 150)\n",
            "/content/ML-MC/seg_train/glacier/16472.jpg (143, 150)\n",
            "/content/ML-MC/seg_train/glacier/11110.jpg (105, 150)\n",
            "/content/ML-MC/seg_train/mountain/5371.jpg (141, 150)\n",
            "/content/ML-MC/seg_train/mountain/6057.jpg (146, 150)\n",
            "/content/ML-MC/seg_train/mountain/5171.jpg (143, 150)\n",
            "/content/ML-MC/seg_train/mountain/14462.jpg (113, 150)\n",
            "/content/ML-MC/seg_train/mountain/18823.jpg (144, 150)\n",
            "/content/ML-MC/seg_train/mountain/8163.jpg (147, 150)\n",
            "/content/ML-MC/seg_train/mountain/14575.jpg (142, 150)\n",
            "/content/ML-MC/seg_train/mountain/16971.jpg (103, 150)\n",
            "/content/ML-MC/seg_train/mountain/7400.jpg (81, 150)\n",
            "/content/ML-MC/seg_train/mountain/11873.jpg (134, 150)\n",
            "/content/ML-MC/seg_train/mountain/17021.jpg (136, 150)\n",
            "/content/ML-MC/seg_train/mountain/13656.jpg (123, 150)\n",
            "/content/ML-MC/seg_train/mountain/9286.jpg (131, 150)\n",
            "/content/ML-MC/seg_train/mountain/13200.jpg (135, 150)\n",
            "/content/ML-MC/seg_train/mountain/16041.jpg (144, 150)\n",
            "/content/ML-MC/seg_train/mountain/6633.jpg (145, 150)\n",
            "/content/ML-MC/seg_train/mountain/4513.jpg (100, 150)\n",
            "/content/ML-MC/seg_train/sea/19551.jpg (113, 150)\n",
            "/content/ML-MC/seg_train/sea/5584.jpg (113, 150)\n",
            "/content/ML-MC/seg_train/sea/357.jpg (140, 150)\n",
            "/content/ML-MC/seg_train/sea/341.jpg (113, 150)\n",
            "/content/ML-MC/seg_train/street/13747.jpg (113, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}